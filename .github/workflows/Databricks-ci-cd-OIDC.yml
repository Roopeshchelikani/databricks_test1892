name: Deploy to Databricks with OIDC

on:
  push:
    branches:
      - main
  workflow_dispatch: # Allows manual triggering for testing

jobs:
  deploy-to-databricks:
    runs-on: ubuntu-latest
    permissions:
      id-token: write      # Required for OIDC to Azure
      contents: read       # Required to checkout the repo

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Login to Azure using OIDC 
        uses: azure/login@v1
        with:
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}

      - name: Get AAD access token for Databricks
        id: get-databricks-token
        run: |
          echo "Fetching token for resource: ${{ secrets.DATABRICKS_HOST_NAME }}" 
          databricks_token=$(az account get-access-token --resource ${{ secrets.DATABRICKS_HOST_NAME }} --query accessToken -o tsv)
          echo "token_value=${databricks_token}" >> $GITHUB_OUTPUT
          echo "::add-mask::${databricks_token}"

      - name: Set up Databricks CLI
        uses: databricks/setup-cli@v0.218.0

      # --- DEBUG STEP: Check Databricks CLI version ---
      - name: Check Databricks CLI version
        run: databricks --version

      # --- DEBUG STEP: List local databricks directory contents ---
      - name: List local databricks directory contents
        run: ls -la ./databricks || echo "./databricks directory is empty or does not exist."

      # --- CRUCIAL DEBUG STEP: Check Databricks CLI configuration ---
      # This step will show if the CLI is correctly picking up the DATABRICKS_HOST and DATABRICKS_TOKEN
      - name: Check Databricks CLI configuration
        env: # Environment variables must be explicitly set for THIS step
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ steps.get-databricks-token.outputs.token_value }}
        run: |
          echo "Checking Databricks CLI config profile 'DEFAULT'..."
          # This command will output the host and token it is using (masked in logs)
          databricks config get --profile DEFAULT 

      - name: Deploy to Databricks Workspace
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ steps.get-databricks-token.outputs.token_value }}
        run: |
          # NOTE: There's an inconsistency here.
          # The echo says /Shared/dev_OIDC_deploy, but the command uses /deployment/dev_OIDC_deploy.
          # Please ensure these paths match your intention. I'll keep the /deployment one for the command as per your last code.
          echo "Deploying notebooks from ./databricks to /deployment/dev_OIDC_deploy on ${DATABRICKS_HOST}"
          
          TARGET_PATH="/deployment/dev_OIDC_deploy"
          SOURCE_PATH="./databricks"

          # 1. Ensure the parent directory exists (e.g., /deployment).
          echo "Ensuring parent directory for ${TARGET_PATH} exists..."
          PARENT_DIR=$(dirname "${TARGET_PATH}")
          databricks workspace mkdirs "${PARENT_DIR}" || true # Create parent dir if it doesn't exist

          # 2. Attempt to delete the target directory if it exists.
          echo "Attempting to delete existing directory ${TARGET_PATH} if it exists..."
          databricks workspace delete "${TARGET_PATH}" --recursive || true # --recursive is correct for directories

          # 3. Import the directory
          echo "Importing notebooks from ${SOURCE_PATH} to ${TARGET_PATH}..."
          # The --debug flag is essential here to get more verbose output if it fails again
          databricks --debug workspace import_dir "${SOURCE_PATH}" "${TARGET_PATH}"
          
          echo "Deployment attempt finished."
